{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Reconstruction Using AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
  
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTRS_NAME = \"lfw_attributes.txt\"\n",
    "\n",
    "IMAGES_NAME = \"lfw-deepfunneled.tgz\"\n",
    "\n",
    "RAW_IMAGES_NAME = \"lfw.tgz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding image from raw bytes\n",
    "\n",
    "Here we use two functions: \n",
    "\n",
    "1. Convert raw matrix to image\n",
    "2. Change color system to RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image_from_raw_bytes(raw_bytes):\n",
    "  img = cv2.imdecode(np.asarray(bytearray(raw_bytes), dtype=np.uint8), 1)\n",
    "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "  return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the LFW dataset and adapting to the format using above function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lfw_dataset(use_raw=False, dx=80, dy=80, dimx=45, dimy=45):\n",
    "    # Reading the attributes from file\n",
    "    df_attrs = pd.read_csv(ATTRS_NAME, sep='\\t', skiprows=1)\n",
    "    df_attrs = pd.DataFrame(df_attrs.iloc[:, :-1].values, columns=df_attrs.columns[1:])\n",
    "    imgs_with_attrs = set(map(tuple, df_attrs[[\"person\", \"imagenum\"]].values))\n",
    "\n",
    "    # Reading images\n",
    "    all_images = []\n",
    "    image_ids = []\n",
    "\n",
    "    with tarfile.open(RAW_IMAGES_NAME if use_raw else IMAGES_NAME) as f:\n",
    "        for m in tqdm.tqdm_notebook(f.getmembers()):\n",
    "            # Only process image files from the compressed data\n",
    "            if m.isfile() and m.name.endswith(\".jpg\"):\n",
    "                # Prepare image\n",
    "                img = decode_image_from_raw_bytes(f.extractfile(m).read())\n",
    "\n",
    "                # Crop only faces and resize it\n",
    "                img = img[dy:-dy, dx:-dx]\n",
    "                img = cv2.resize(img, (dimx, dimy))\n",
    "\n",
    "                # Parse person and append it to the collected data\n",
    "                fname = os.path.split(m.name)[-1]\n",
    "                fname_splitted = fname[:-4].replace('_', ' ').split()\n",
    "                person_id = ' '.join(fname_splitted[:-1])\n",
    "                photo_number = int(fname_splitted[-1])\n",
    "                if (person_id, photo_number) in imgs_with_attrs:\n",
    "                    all_images.append(img)\n",
    "                    image_ids.append({'person': person_id, 'imagenum': photo_number})\n",
    "\n",
    "    image_ids = pd.DataFrame(image_ids)\n",
    "    all_images = np.stack(all_images).astype('uint8')\n",
    "\n",
    "    # Preserve image_ids order\n",
    "    all_attrs = image_ids.merge(df_attrs, on=('person', 'imagenum')).drop([\"person\", \"imagenum\"], axis=1)\n",
    "\n",
    "    return all_images, all_attrs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
