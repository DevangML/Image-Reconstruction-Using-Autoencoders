{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Reconstruction Using AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTRS_NAME = \"lfw_attributes.txt\"\n",
    "\n",
    "IMAGES_NAME = \"lfw-deepfunneled.tgz\"\n",
    "\n",
    "RAW_IMAGES_NAME = \"lfw.tgz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding image from raw bytes\n",
    "\n",
    "Here we use two functions: \n",
    "\n",
    "1. Convert raw matrix to image\n",
    "2. Change color system to RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image_from_raw_bytes(raw_bytes):\n",
    "  img = cv2.imdecode(np.asarray(bytearray(raw_bytes), dtype=np.uint8), 1)\n",
    "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "  return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the LFW dataset and adapting to the format using above function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lfw_dataset(use_raw=False, dx=80, dy=80, dimx=45, dimy=45):\n",
    "    # Reading the attributes from file\n",
    "    df_attrs = pd.read_csv(ATTRS_NAME, sep='\\t', skiprows=1)\n",
    "    df_attrs = pd.DataFrame(df_attrs.iloc[:, :-1].values, columns=df_attrs.columns[1:])\n",
    "    imgs_with_attrs = set(map(tuple, df_attrs[[\"person\", \"imagenum\"]].values))\n",
    "\n",
    "    # Reading images\n",
    "    all_images = []\n",
    "    image_ids = []\n",
    "\n",
    "    with tarfile.open(RAW_IMAGES_NAME if use_raw else IMAGES_NAME) as f:\n",
    "        for m in tqdm.tqdm_notebook(f.getmembers()):\n",
    "            # Only process image files from the compressed data\n",
    "            if m.isfile() and m.name.endswith(\".jpg\"):\n",
    "                # Prepare image\n",
    "                img = decode_image_from_raw_bytes(f.extractfile(m).read())\n",
    "\n",
    "                # Crop only faces and resize it\n",
    "                img = img[dy:-dy, dx:-dx]\n",
    "                img = cv2.resize(img, (dimx, dimy))\n",
    "\n",
    "                # Parse person and append it to the collected data\n",
    "                fname = os.path.split(m.name)[-1]\n",
    "                fname_splitted = fname[:-4].replace('_', ' ').split()\n",
    "                person_id = ' '.join(fname_splitted[:-1])\n",
    "                photo_number = int(fname_splitted[-1])\n",
    "                if (person_id, photo_number) in imgs_with_attrs:\n",
    "                    all_images.append(img)\n",
    "                    image_ids.append({'person': person_id, 'imagenum': photo_number})\n",
    "\n",
    "    image_ids = pd.DataFrame(image_ids)\n",
    "    all_images = np.stack(all_images).astype('uint8')\n",
    "\n",
    "    # Preserve image_ids order\n",
    "    all_attrs = image_ids.merge(df_attrs, on=('person', 'imagenum')).drop([\"person\", \"imagenum\"], axis=1)\n",
    "\n",
    "    return all_images, all_attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Autencoder Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X, attr = load_lfw_dataset(use_raw=True, dimx=32, dimy=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype('float32') / 255.0 - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.max(), X.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_image(x):\n",
    "    plt.imshow(np.clip(x + 0.5, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(X[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test = train_test_split(X, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Flatten, Reshape, Input, InputLayer\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "def build_autoencoder(img_shape, code_size):\n",
    "    # The encoder\n",
    "    encoder = Sequential()\n",
    "    encoder.add(InputLayer(img_shape))\n",
    "    encoder.add(Flatten())\n",
    "    encoder.add(Dense(code_size))\n",
    "\n",
    "    # The decoder\n",
    "    decoder = Sequential()\n",
    "    decoder.add(InputLayer((code_size,)))\n",
    "    decoder.add(Dense(np.prod(img_shape))) # np.prod(img_shape) is the same as 32*32*3, it's more generic than saying 3072\n",
    "    decoder.add(Reshape(img_shape))\n",
    "\n",
    "    return encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as (32,32,3), we neglect the number of instances from shape\n",
    "IMG_SHAPE = X.shape[1:]\n",
    "encoder, decoder = build_autoencoder(IMG_SHAPE, 32)\n",
    "\n",
    "inp = Input(IMG_SHAPE)\n",
    "code = encoder(inp)\n",
    "reconstruction = decoder(code)\n",
    "\n",
    "autoencoder = Model(inp,reconstruction)\n",
    "autoencoder.compile(optimizer='adamax', loss='mse')\n",
    "\n",
    "print(autoencoder.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = autoencoder.fit(x=X_train, y=X_train, epochs=20, validation_data=[X_test, X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(img,encoder,decoder):\n",
    "    \"\"\"Draws original, encoded and decoded images\"\"\"\n",
    "    # img[None] will have shape of (1, 32, 32, 3) which is the same as the model input\n",
    "    code = encoder.predict(img[None])[0]\n",
    "    reco = decoder.predict(code[None])[0]\n",
    "\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.title(\"Original\")\n",
    "    show_image(img)\n",
    "\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.title(\"Code\")\n",
    "    plt.imshow(code.reshape([code.shape[-1]//2,-1]))\n",
    "\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.title(\"Reconstructed\")\n",
    "    show_image(reco)\n",
    "    plt.show()\n",
    "\n",
    "for i in range(5):\n",
    "    img = X_test[i]\n",
    "    visualize(img,encoder,decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gaussian_noise(X, sigma=0.1):\n",
    "    noise = np.random.normal(loc=0.0, scale=sigma, size=X.shape)\n",
    "    return X + noise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
